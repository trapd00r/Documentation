From zsh-users-return-12158-mason-zsh=primenet.com.au@sunsite.dk Thu Nov 01 07:27:11 2007
Return-Path: <zsh-users-return-12158-mason-zsh=primenet.com.au@sunsite.dk>
Delivered-To: mason-zsh@primenet.com.au
Received: (qmail 17131 invoked from network); 1 Nov 2007 07:27:02 -0000
X-Spam-Checker-Version: SpamAssassin 3.2.3 (2007-08-08) on f.primenet.com.au
X-Spam-Level: 
X-Spam-Status: No, score=-2.6 required=5.0 tests=AWL,BAYES_00 autolearn=ham
	version=3.2.3
Received: from news.dotsrc.org (HELO a.mx.sunsite.dk) (130.225.247.88)
  by ns1.primenet.com.au with SMTP; 1 Nov 2007 07:27:02 -0000
Received-SPF: none (ns1.primenet.com.au: domain at sunsite.dk does not designate permitted sender hosts)
Received: (qmail 5595 invoked from network); 1 Nov 2007 07:26:55 -0000
Received: from sunsite.dk (130.225.247.90)
  by a.mx.sunsite.dk with SMTP; 1 Nov 2007 07:26:55 -0000
Received: (qmail 17933 invoked by alias); 1 Nov 2007 07:26:46 -0000
Mailing-List: contact zsh-users-help@sunsite.dk; run by ezmlm
Precedence: bulk
X-No-Archive: yes
Delivered-To: mailing list zsh-users@sunsite.dk
X-Seq: 12158
Received: (qmail 17916 invoked from network); 1 Nov 2007 07:26:45 -0000
Received: from news.dotsrc.org (HELO a.mx.sunsite.dk) (130.225.247.88)
  by sunsite.dk with SMTP; 1 Nov 2007 07:26:45 -0000
Received: (qmail 4295 invoked from network); 1 Nov 2007 07:26:45 -0000
Received: from wa-out-1112.google.com (209.85.146.181)
  by a.mx.sunsite.dk with SMTP; 1 Nov 2007 07:26:39 -0000
Received: by wa-out-1112.google.com with SMTP id j4so526921wah
        for <zsh-users@sunsite.dk>; Thu, 01 Nov 2007 00:26:36 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=beta;
        h=domainkey-signature:received:received:message-id:date:from:to:subject:in-reply-to:mime-version:content-type:content-transfer-encoding:content-disposition:references;
        bh=8JkGUQoAoGY7E+/vRMZnM0Pv5GdQHkSq+EaU3paD9iI=;
        b=petcmJJu6tQf2x5ABadHWYEz/mUbXuP8viN41ckARxljGS1j4njlFQF042f5PQVwqj7KvvgV3m083nugi0MlkNNkhig+6oa1mayVUkoBXXZ+MSfaZWmhGePWXer8mWHoanm5xIAICS1A62Pv+mEm3Bty74Ha9bZ6j2gBxRpFEzc=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=beta;
        h=received:message-id:date:from:to:subject:in-reply-to:mime-version:content-type:content-transfer-encoding:content-disposition:references;
        b=kH0bJy/ge3Rf7NEyuuSQkug1ik3+Rj0duP7MlZdiZS8KxGA5wiJ0obB42cWzOa0miC5NBcndikCehrx+rjAWJpaOnqQMNZyBHQP68uphR5rbmg+a6yfBn1AfRw0u6vjsMLHLQt3gY1ic8QgUwKNA6DgxhJGjlsbkNejxVJqNQUc=
Received: by 10.115.93.16 with SMTP id v16mr285207wal.1193901996163;
        Thu, 01 Nov 2007 00:26:36 -0700 (PDT)
Received: by 10.115.23.18 with HTTP; Thu, 1 Nov 2007 00:26:36 -0700 (PDT)
Message-ID: <82839db60711010026r5b28c397yb4be5136d655f7d7@mail.gmail.com>
Date: Thu, 1 Nov 2007 08:26:36 +0100
From: "Anonymous bin ich" <ichbinanon@gmail.com>
To: zsh-users@sunsite.dk
Subject: Re: copying a million small files between disks?
In-Reply-To: <d6d6637f0710311841q12f8e2bem1ca8ee166289dfe0@mail.gmail.com>
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit
Content-Disposition: inline
References: <6a42eec70710311440u52556985wda68ce326f4a0417@mail.gmail.com>
	 <d6d6637f0710311841q12f8e2bem1ca8ee166289dfe0@mail.gmail.com>

I ran into the same problem, and used find. I had to replace all
instances of ls in shell scripts:

ls *qj*par 2>|/dev/null|wc -l

with

find -maxdepth 1 -name \*qj\*par 2>|/dev/null|wc -l

Also, completion will be very slow so you might want to disable it if
pressing TAB is in your habit :)

On 11/1/07, Christopher Browne <cbbrowne@gmail.com> wrote:
> On 10/31/07, sam reckoner <sam.reckoner@gmail.com> wrote:
> > I'm not exaggerating. I have over one million small files that like to
> > move between disks. The problem is that even getting a directory
> > listing takes forever.
> >
> > Is there a best practice for this?
> >
> > I don't really need the directory listing, I just need to move all the
> > files. I have been using rsync, but that takes a very long time to
> > generate the list of files to be moved.
> >
> > Any alternatives?
>
> Yeah, I'd use find.
>
> The fundamental problem with ls, which you're clearly running into, is
> that when there are a million files, not only do you:
>
> a) Have to read the directory entries, but
>
> b) They will all have to be read into memory (in some form of array), and
>
> c) Then they get sorted (presumably generating a *second* array,
> though possibly not).
>
> You're getting your lunch eaten by b) and c).
>
> You might try:
>    "find /path/where/all/the/files/are | xargs cp -I {}
> /path/that/is/destination"
>
> That will skip steps b and c.
> --
> http://linuxfinances.info/info/linuxdistributions.html
> "...  memory leaks  are  quite acceptable  in  many applications  ..."
> (Bjarne Stroustrup, The Design and Evolution of C++, page 220)
>


-- 
Regards,

