From zsh-workers-return-10447-mason-zsh=primenet.com.au@sunsite.auc.dk Tue Apr 04 03:24:05 2000
Return-Path: <zsh-workers-return-10447-mason-zsh=primenet.com.au@sunsite.auc.dk>
Delivered-To: mason-zsh@primenet.com.au
Received: (qmail 11509 invoked from network); 4 Apr 2000 03:24:04 -0000
Received: from sunsite.auc.dk (130.225.51.30)
  by ns1.primenet.com.au with SMTP; 4 Apr 2000 03:24:04 -0000
Received: (qmail 18014 invoked by alias); 4 Apr 2000 03:23:58 -0000
Mailing-List: contact zsh-workers-help@sunsite.auc.dk; run by ezmlm
Precedence: bulk
X-No-Archive: yes
Delivered-To: mailing list zsh-workers@sunsite.auc.dk
X-Seq: 10447
Received: (qmail 18002 invoked from network); 4 Apr 2000 03:23:58 -0000
Date: Mon, 3 Apr 2000 23:23:51 -0400
From: Clint Adams <schizo@debian.org>
To: Peter Stephenson <pws@pwstephenson.fsnet.co.uk>
Cc: Zsh hackers list <zsh-workers@sunsite.auc.dk>
Subject: Re: sourceforge issues
Message-ID: <20000403232351.B1658@scowler.net>
References: <E12cDij-0004C5-00.2000-04-03-21-45-13@mail3.svr.pol.co.uk>
Mime-Version: 1.0
Content-Type: text/plain; charset=us-ascii
User-Agent: Mutt/1.0.1i
In-Reply-To: <E12cDij-0004C5-00.2000-04-03-21-45-13@mail3.svr.pol.co.uk>; from pws@pwstephenson.fsnet.co.uk on Mon, Apr 03, 2000 at 09:45:11PM +0100

> - Idle question, but does anyone know of an automated way of getting the
>   latest version of a file from the CVS archive via the web, without CVS?
>   What I mean is, can you tell people to `get the latest version of
>   _path_files from <URL_prefix>Completion/Core/_path_files<URL_suffix>'?
>   As far as I can see the cvsweb.cgi interface needs you to tell it a
>   version number which would put paid to this.  The may be some feature
>   I haven't seen.

Stock cvsweb checks the revision for the Perl RE /^[\d\.]+$/, so
while CVS will happily take a -r HEAD, cvsweb won't.  I assume that
SourceForge's custom version doesn't have this changed.

I see two other groups on our server have their own cvsweb.cgi,
so one might assume that we can put a custom version up ourselves.

Alternately, someone could set up a cronjob to export -r HEAD
to the web dir repeatedly, but that's a bit uglier, IMO.

